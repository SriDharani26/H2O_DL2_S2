{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c412b4130e754f30a8671aff28cec72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38a10ec14d724ce6ba74cd22942dcea9",
              "IPY_MODEL_6f9450db9cfd4fd1963561b3ba38f387",
              "IPY_MODEL_e3d435cd5ac14ae395a9672ae7d3f514"
            ],
            "layout": "IPY_MODEL_ec91081ec2584ab39cc3ee5a873b0893"
          }
        },
        "38a10ec14d724ce6ba74cd22942dcea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feff141b3b8f4833ab0d8bf7fd49e84d",
            "placeholder": "​",
            "style": "IPY_MODEL_1601e80577f64136be6a7a0102a8d4de",
            "value": "Map: 100%"
          }
        },
        "6f9450db9cfd4fd1963561b3ba38f387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb1de689d27c47cd8a79195737df2cea",
            "max": 214,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_698333caa2364f3daffdfd79d9421585",
            "value": 214
          }
        },
        "e3d435cd5ac14ae395a9672ae7d3f514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4aecdd386bc46888e984f684fbd3192",
            "placeholder": "​",
            "style": "IPY_MODEL_316a93efe6984c6585f02ffda6e4d1a3",
            "value": " 214/214 [00:01&lt;00:00, 217.66 examples/s]"
          }
        },
        "ec91081ec2584ab39cc3ee5a873b0893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feff141b3b8f4833ab0d8bf7fd49e84d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1601e80577f64136be6a7a0102a8d4de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb1de689d27c47cd8a79195737df2cea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698333caa2364f3daffdfd79d9421585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4aecdd386bc46888e984f684fbd3192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "316a93efe6984c6585f02ffda6e4d1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32acd1a64282401b98d2e3d200db6f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a9f58c1d4ac4b74985f8bf137f96b2f",
              "IPY_MODEL_43cb02f3f70043ceb787c03eb63d7ed7",
              "IPY_MODEL_296ad9aef3264b9b90c32d59229d10b9"
            ],
            "layout": "IPY_MODEL_91ad8ab6a9874fd3b921306d0c71c871"
          }
        },
        "5a9f58c1d4ac4b74985f8bf137f96b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1af8c8d8b8543e09d3959bed7eafef6",
            "placeholder": "​",
            "style": "IPY_MODEL_6cde556aca28433ea77287f1b2f54ad0",
            "value": "Map: 100%"
          }
        },
        "43cb02f3f70043ceb787c03eb63d7ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7391cd2e1bc749d7bfead18bc5180343",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1744ed5f1dc94424b0cd9ca52b9d2f64",
            "value": 25
          }
        },
        "296ad9aef3264b9b90c32d59229d10b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972e2c1f9c1a477ba3f19fb96414f2a5",
            "placeholder": "​",
            "style": "IPY_MODEL_2d42e2b84e9d4600aee646ea60f8678c",
            "value": " 25/25 [00:00&lt;00:00, 187.57 examples/s]"
          }
        },
        "91ad8ab6a9874fd3b921306d0c71c871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1af8c8d8b8543e09d3959bed7eafef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cde556aca28433ea77287f1b2f54ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7391cd2e1bc749d7bfead18bc5180343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1744ed5f1dc94424b0cd9ca52b9d2f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "972e2c1f9c1a477ba3f19fb96414f2a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d42e2b84e9d4600aee646ea60f8678c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5wMxZSvLshy",
        "outputId": "a40e3325-76d7-4d95-ed6d-eb2396fe797f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6KXxsw8kAcH",
        "outputId": "06b21b38-d813-4240-f7f7-988f06a95338"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers==4.19.2\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "ZW7IyQwukLls"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "import pandas as pd\n",
        "df= pd.read_csv('/content/drive/MyDrive/CodeCycle/articlesSet.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "grxYg9RCNK_s",
        "outputId": "5bbb974c-4d83-423a-f006-a9eac606c309"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              title  \\\n",
              "0               Mental Note Vol. 24   \n",
              "1         Your Brain On Coronavirus   \n",
              "2                    Mind Your Nose   \n",
              "3          The 4 Purposes of Dreams   \n",
              "4  Surviving a Rod Through the Head   \n",
              "\n",
              "                                             summary  \\\n",
              "0  Irrespective of gender, race, age or religion ...   \n",
              "1  These pathways converge and mediate brain heal...   \n",
              "2  Learning a new language or reading more books ...   \n",
              "3  Passionate about the synergy between science a...   \n",
              "4  What about him?” Well, let’s just say that he ...   \n",
              "\n",
              "                                             content  \n",
              "0  Photo by Josh Riemer on Unsplash<|n|><|n|>Merr...  \n",
              "1  Your Brain On Coronavirus<|n|><|n|>A guide to ...  \n",
              "2  Mind Your Nose<|n|><|n|>How smell training can...  \n",
              "3  Passionate about the synergy between science a...  \n",
              "4  You’ve heard of him, haven’t you? Phineas Gage...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db2ba537-d420-4946-8706-b35ba7f53cf9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mental Note Vol. 24</td>\n",
              "      <td>Irrespective of gender, race, age or religion ...</td>\n",
              "      <td>Photo by Josh Riemer on Unsplash&lt;|n|&gt;&lt;|n|&gt;Merr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Your Brain On Coronavirus</td>\n",
              "      <td>These pathways converge and mediate brain heal...</td>\n",
              "      <td>Your Brain On Coronavirus&lt;|n|&gt;&lt;|n|&gt;A guide to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mind Your Nose</td>\n",
              "      <td>Learning a new language or reading more books ...</td>\n",
              "      <td>Mind Your Nose&lt;|n|&gt;&lt;|n|&gt;How smell training can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The 4 Purposes of Dreams</td>\n",
              "      <td>Passionate about the synergy between science a...</td>\n",
              "      <td>Passionate about the synergy between science a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Surviving a Rod Through the Head</td>\n",
              "      <td>What about him?” Well, let’s just say that he ...</td>\n",
              "      <td>You’ve heard of him, haven’t you? Phineas Gage...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db2ba537-d420-4946-8706-b35ba7f53cf9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db2ba537-d420-4946-8706-b35ba7f53cf9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db2ba537-d420-4946-8706-b35ba7f53cf9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-45f1efc4-816f-4f25-8092-0eb6d67113b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-45f1efc4-816f-4f25-8092-0eb6d67113b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-45f1efc4-816f-4f25-8092-0eb6d67113b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1155,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1155,\n        \"samples\": [\n          \"How I Built a Lasting Exercise Habit\",\n          \"How Can People Be Incentivised to Solve the Climate Crisis?\",\n          \"How to Silence the Haters in Your Head as You Write\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1059,\n        \"samples\": [\n          \"In this post, I\\u2019d like to show how to quickly create a Tableau-like BI application on top of your data in a Jupyter Notebook using the atoti python module.You can open the URL of the app by running<|n|><|n|>session.url<|n|><|n|>Next step is to load the data from a pandas dataframe into the app engine (creating an in-memory datastore).Finally, the create_cube command is populating measures and dimensions.<|n|><|n|>Later if you want, you can load more data sources and link them together in a snowflake-type of data schema.\",\n          \"And\\u2026 you just have been told by scientists that that comet is racing toward the Earth and it\\u2019s going to kill everybody and everything in a big fiery storm, [but] nobody notices the comet.Dr. Bednarek also describes it as \\u201can anxiety about the future and a trauma that we have not experienced yet, but that we know is going to come our way.\\u201d She says that although climate change anxiety is a relatively new term, it\\u2019s not new as a phenomenon.And\\u2026you just have been told by scientists that that comet is racing toward the Earth and it\\u2019s going to kill everybody and everything in a big fiery storm, [but] nobody notices the comet.In the video, the people who talk about their experience also refer to thoughts that make them feel eco-anxious.<|n|><|n|>For instance, one of them says that when he thinks about the fact that other parts of the world are more severely impacted by climate change, that triggers his anxiety.Then, we will all feel eco-anxious, because it won\\u2019t longer have to do with mere thoughts about events happening \\u201csomewhere else\\u201d, but with experiences related to events happening in the cities we all live in.<|n|><|n|>References:\",\n          \"Photo by rawpixel on Unsplash<|n|><|n|>It is very easy these days to find ourselves overcommitted and overwhelmed as we try to \\u201cfit it all in.\\u201d<|n|><|n|>There are many demands for our time and attention, pulling us in a thousand different directions, and countless distractions to derail us from what really matters.<|n|><|n|>It is all too common to find ourselves busy nonstop throughout the day without any space for real thinking.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1149,\n        \"samples\": [\n          \"How to come up with a name for your new business<|n|><|n|>More than 600,000 new businesses launch every year \\u2014 how can you come up with a name that stands out from the crowd?<|n|><|n|>Photo by bruce mars on Unsplash<|n|><|n|>\\u201cNames have power.\\u201d \\u2015 Rick Riordan<|n|><|n|>A name is the face of your business. It needs to capture your essence, values, and what makes you different from the competition. It should be the most unique, yet relatable thing about your brand.<|n|><|n|>That\\u2019s a lot of pressure to hang on a few words.<|n|><|n|>Especially because what makes a name \\u201cgood\\u201d is highly subjective, and if you get it wrong the stakes are high.<|n|><|n|>So how can you create a name for your new company that gets people excited to buy it?<|n|><|n|>Photo by \\u00c1lvaro Serrano on Unsplash<|n|><|n|>What makes a great name for a new business?<|n|><|n|>Although whether a name is \\u201cgood\\u201d or \\u201cbad\\u201d is subjective, there are few traits that successful names share:<|n|><|n|>Familiarity: This characteristic matters more when you\\u2019re naming a brand that is part of a master brand or portfolio. For instance, Apple\\u2019s naming convention for its mobile products. Each began with \\u201ci\\u201d (iPad, iPod, iPhone). BMW has a numeric system that puts every car into a hierarchy based on performance (118i, 320d, 520d xDrive).<|n|><|n|>Think about the typical naming conventions of your market. How can you create a naming convention that customers will learn to know and love?<|n|><|n|>2. Distinctiveness: How unique is your company\\u2019s name? The uniqueness of your name should relate to how unique your brand\\u2019s offering is.<|n|><|n|>Think about your market \\u2014 what naming conventions appear repeatedly? Can you break these and create your own, or twist the convention so that your name stands out from the crowd?<|n|><|n|>Photo by Milivoj Kuhar on Unsplash<|n|><|n|>A basic process for naming a new company<|n|><|n|>1. Before you do anything, create a brief<|n|><|n|>A brief is a set of instructions or guide rails for a project.<|n|><|n|>Briefs are essential when starting a project because they define measures for success. In an agency or consultancy, the brief also helps inspire the writers who will be creating the name.<|n|><|n|>Some questions our brief needs to answer include:<|n|><|n|>Who is the target audience for this business?<|n|><|n|>Should it be abstract (like Apple) or descriptive (like PlayStation)?<|n|><|n|>Should it be long or short?<|n|><|n|>Are there brand naming conventions we need to keep in mind (like the iPad and iPhone)?<|n|><|n|>Should it be a real word (like Blackberry) or a new word (like Google)?<|n|><|n|>Should it support a mother brand (like DoubleTree by Hilton) or be able to stand alone (like Starbucks)?<|n|><|n|>Because a good name is so subjective, you\\u2019ll need to make sure there are agreed parameters for what makes the name \\u201cright\\u201d for you and/or your client.<|n|><|n|>2. Research<|n|><|n|>First, we need to answer some fundamental questions about the world our name will live in, like:<|n|><|n|>Who are our competitors in this space?<|n|><|n|>What\\u2019s a sample of their company names and types?<|n|><|n|>What are some naming conventions in this category we\\u2019d like to adopt or avoid?<|n|><|n|>What brand attributes do their names convey?<|n|><|n|>Are there any \\u201cbig name\\u201d territories we want to avoid (such as naming a new laptop iCompute)?<|n|><|n|>3. Brainstorm (with parameters)<|n|><|n|>Before we begin our session, it\\u2019s essential to realize that brainstorming without guardrails will fail. Research shows that loose and free brainstorming sessions are less productive than approaches with more structure.<|n|><|n|>Thought starters and parameters are needed to establish what we\\u2019re looking for.<|n|><|n|>A great place to start when brainstorming is a four-quadrant grid that establishes the common types of names:<|n|><|n|>Functional / Descriptive Names: These are the most straightforward names. They tell customers exactly what the business does. \\u201cGary\\u2019s Plumbing\\u201d or the \\u201cKline Branding Company\\u201d are examples of Functional Names. Invented Names: Invented names are those that include words not yet seen in language. Think \\u201cGoogle,\\u201d \\u201cKleenex,\\u201d or \\u201cOreo.\\u201d Experiential Names: These names connect to experiences people are familiar with, or can easily relate to. Examples include \\u201cSafari,\\u201d \\u201cExplorer,\\u201d \\u201cAmazon,\\u201d and \\u201cSweaty Betty.\\u201d Evocative Names: These names evoke the spirit of a brand and how it differentiates itself from competitors. Think \\u201cVirgin Airlines,\\u201d \\u201cUber,\\u201d \\u201cBumble,\\u201d and \\u201cLululemon.\\u201d<|n|><|n|>4. Vet potential names<|n|><|n|>There are two parts to this process:<|n|><|n|>First, we\\u2019ll legally vet our names to make sure we can use them.<|n|><|n|>Second, we\\u2019ll use an objective scorecard to make sure our names are fundamentally sound choices (and to stack-rank them).<|n|><|n|>The legal vetting phase<|n|><|n|>Note: I suggest that you consult with an attorney during this section, as they\\u2019ll be the best person to advise you on if the name is legally available. The list below is no substitute for a lawyer\\u2019s input.<|n|><|n|>Although you will get lawyers involved eventually, a \\u201cfirst vet\\u201d of potential names will help you eliminate obviously problematic ones.<|n|><|n|>Here\\u2019s a quick list of places to test your names in the wild, to see if they pass the \\u201ctrademark\\u201d test:<|n|><|n|>Google it.<|n|><|n|>Visit the U.S. Patent and Trademark website (if you\\u2019re in the U.S.).<|n|><|n|>Put your potential name into Google Translate and see if it might prove problematic in other languages.<|n|><|n|>Search social media to make sure potential usernames are available.<|n|><|n|>Do a domain name search to see if your name is readily available (or affordable to buy).<|n|><|n|>Use Namechk to search social media for similar names.<|n|><|n|>Use Google Trends to see how often people search for a keyword.<|n|><|n|>The scorecard phase<|n|><|n|>Once you have a vetted selection of names, you can go down each of the criteria and score the name from 0\\u201310. Then tally the numbers and see which of the names is the strongest overall.<|n|><|n|>Source: Example created by the author<|n|><|n|>5. Bring the name to life and test it<|n|><|n|>Now it\\u2019s time to bring our names to life by exploring them through creative elements. This might include mocking them up in logos, creating sample labels, merchandise, or websites.<|n|><|n|>Note: If you lack the resources to bring these names to life right now, you can test only names with customers \\u2014 but be wary that creative elements can radically change perceptions of a name.<|n|><|n|>Narrow down your list using the previous step to your top five choices.<|n|><|n|>Use creative mockups to bring your elements to life.<|n|><|n|>Use a low-cost consumer survey like SurveyMonkey, Amazon MTurk or Google Consumer Surveys to get your names in front of as many of your potential customers as possible.<|n|><|n|>Use this feedback as data to inform your final name choice.<|n|><|n|>Photo by Jessica Ruscello on Unsplash<|n|><|n|>The bottom line<|n|><|n|>\\u201cDetermine who you are and what your brand is, and what you\\u2019re not. The rest of it is just a lot of noise.\\u201d \\u2014 Geoffrey Zakarian<|n|><|n|>A company\\u2019s name is its face to the world. People will learn from it, judge it, and use it as a shortcut to understanding your brand.<|n|><|n|>But no matter how perfect, a name can\\u2019t save a bad business. And it won\\u2019t sink an amazing one.<|n|><|n|>At the end of the day, your business\\u2019 name must reflect your brand and its values. Otherwise, as Geoffrey Zakarian says in the quote above, it will just be \\u201ca lot of noise.\\u201d\",\n          \"This scanning electron microscope image shows the new coronavirus, SARS-CoV-2, in yellow and isolated from a U.S. patient, emerging from the surface of cells (blue/pink) cultured in the lab. Credit: NIAID-RML<|n|><|n|>How Long Coronavirus Survives on Hard and Soft Surfaces<|n|><|n|>It just sits there for hours, even days, waiting for a new host to pick it up<|n|><|n|>When a new virus emerges, among the many things scientists do not know is how long it survives outside its targeted hosts. For the new coronavirus, SARS-CoV-2, we humans are the host. And scientists now have an idea for how long this thing can remain viable when it gets deposited on various surfaces, typically by a sneeze or a cough.<|n|><|n|>Viruses are not technically living things. To endure, they need to get inside us, invade our cells, then hijack the nuclear machinery of life. The cells of a person infected with SARS-CoV-2 reproduce the coronavirus, and the person suffers the symptoms of COVID 19.<|n|><|n|>Somewhat lost amid all the news lately is new research published March 17 in the New England Journal of Medicine, results that had circulated for about two weeks prior to the formal publication, and which I noted the other day in my COVID-19 FAQ. The research reveals some figures I found startling, so it seems important to highlight it separately. The coronavirus was found to last up to\\u2026<|n|><|n|>3 hours in aerosols (airborne droplets)<|n|><|n|>4 hours on copper<|n|><|n|>24 hours on cardboard<|n|><|n|>3 days on plastic or stainless steel<|n|><|n|>\\u201cThe results provide key information about the stability of SARS-CoV-2, which causes COVID-19 disease, and suggests that people may acquire the virus through the air and after touching contaminated objects,\\u201d say the researchers, who are from UCLA, Princeton University, the National Institutes of Health and the Centers for Disease Control and Prevention.<|n|><|n|>Interestingly, the stability of this new coronavirus on surfaces was found to be similar to that of its cousin that caused the SARS outbreak back in 2002 and 2003, which was contained after infecting about 8,000 people and killing 774. And that similarity \\u201cunfortunately fails to explain why COVID-19 has become a much larger outbreak,\\u201d the researchers say. \\u201cIf the viability of the two coronaviruses is similar, why is SARS-CoV-2 [the new one] resulting in more cases? Emerging evidence suggests that people infected with SARS-CoV-2 might be spreading virus without recognizing, or prior to recognizing, symptoms. This would make disease control measures that were effective against SARS-CoV-1 less effective against its successor.\\u201d<|n|><|n|>That statement refers to so-called super-spreaders, who are infected with the coronavirus, but have no symptoms (or maybe are mildly sick and think they just have a cold or a touch of the flu, or that it\\u2019s nothing) and who then spread it widely. Even someone who ends up with severe symptoms can spread the disease during the incubation period of the virus, a period of 2 to 14 days (median of about 5 days) before symptoms appear.<|n|><|n|>The survivability of this new germ shows why it is so important to sanitize surfaces, avoid shaking hands, do the social distancing thing, avoid touching your face, and frequently and properly wash your hands (20 seconds of scrubbing with soap). The CDC has detailed recommendations for disinfecting hard and soft surfaces in your home, here.\",\n          \"Long or Short: Which Headlines Are Better?<|n|><|n|>The research is divided, but you don\\u2019t have to choose<|n|><|n|>Illustration by Cynthia Marinakos.<|n|><|n|>I spent over an hour today browsing reputable sites for the answer to the question: Are long or short headlines better? In between running to the couch to comfort my seven-year-old who was freaked out by the thunderstorm bellowing through our home, here\\u2019s what I discovered:<|n|><|n|>Some tell us the ideal blog post headline length is 60 characters. Others recommend 90\\u201399 character headlines because they increase click-through rates by 0.43%.<|n|><|n|>Then it also depends on what platform you\\u2019re writing on. For instance, 40 to 49 characters are ideal for LinkedIn headlines as these were found to receive the highest number of post views overall.<|n|><|n|>In The Anatomy of a Perfect Blog Post, Hubspot informs us that headlines between eight and 12 words are shared most often on Twitter. And headlines between 12 and 14 words are liked most often on Facebook.<|n|><|n|>Backlinko analyzed 912 million blog posts and tells us that \\u201cvery long\\u201d headlines outperform short headlines \\u2014 14 to 17 words are the way to go, generating 76.7% more social shares than short headlines.<|n|><|n|>Buffer tells us that according to science, the ideal length of a headline is six words since we absorb only the first three words and the last three words of a headline.<|n|><|n|>Then there\\u2019s Google search to consider:<|n|><|n|>How many characters will appear in search results before the headline gets cut off?<|n|><|n|>A Google forum product expert tells us it\\u2019s not about the number of characters \\u2014 it\\u2019s a certain width in pixels that limits what is shown of a title. This width roughly translates into something between 60 and 70 characters.<|n|><|n|>And then I was thrilled to find this, which none of the others mentioned at all: a cross-sectional study of 22 scientific journals discovered that longer titles seem to be associated with higher citation rates.<|n|><|n|>The authors conclude that editors who insist on short and concise titles need to update the guidelines for authors so there\\u2019s more flexibility in title length.<|n|><|n|>So are long or short headlines better?<|n|><|n|>It makes sense that the more descriptive a title, the more a reader will know what to expect.<|n|><|n|>But there\\u2019s such conflict between research, I\\u2019m not convinced that headline length is really that important.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df=df.dropna()\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fwo9psdNlkK",
        "outputId": "3299a1e3-0d33-46f1-8ada-e2390aee36f9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1155, 3)\n",
            "(1062, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['length'] = df.content.map(lambda x: len(x.split(\" \")))\n"
      ],
      "metadata": {
        "id": "MliSUbw6Ns48"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numOfWords=df.length\n",
        "from matplotlib import pyplot as plt\n",
        "fig= plt.figure(figsize =(5, 3))\n",
        "plt.hist(numOfWords.to_numpy(), bins = [0,500,1000,1500,2000,2500,3000,3500,4000,5000,6000,7000,8000,9000])\n",
        "plt.title(\"Word count distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "Fw5yccyXN_rA",
        "outputId": "f8de8645-1df3-430f-ce66-009e57e7db97"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tempDf=df[df.length<=800]\n",
        "tempDf =tempDf[tempDf.length>=100]\n",
        "tempDf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aht3rzOrOqRh",
        "outputId": "400a0da1-960c-49a1-f999-8b8bbee7531e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(536, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('allenai/led-base-16384')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK_IxX7fO8w8",
        "outputId": "f0d62d89-0786-480a-c32f-b356fb5dc6cc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/allenai/led-base-16384/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ec844bead6f5bbcd6ac727b57e595c2ba40b0970f91cb923423773f72fe1702f.898baac75d55d484b1b1de95b8ab791987c78591acf36ce6131b56d0d2d26af7\n",
            "Model config LEDConfig {\n",
            "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"LEDForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_window\": [\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_decoder_position_embeddings\": 1024,\n",
            "  \"max_encoder_position_embeddings\": 16384,\n",
            "  \"model_type\": \"led\",\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/4fb25bb1f9a942a2e2930029211b4a7deaeb18b62f6e5ce6d59730c90da51373.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
            "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/087e8f4306cbf22e21907929074344a3b0a46bd680a118eb6267cd5a2bcec5b2.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/05da652a7fca41c1c18027c1201e473217bb373e370d1283e3de49d5880cbf0c.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0\n",
            "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/86288ba22bce9550d76e9b26722ee92ae5921ae9285ccbc2904e9a5ad7199b73.cfc08f03f72cde495bd6b3dd3252bca130b3437de370856d084d1453c58b6fea\n",
            "loading configuration file https://huggingface.co/allenai/led-base-16384/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ec844bead6f5bbcd6ac727b57e595c2ba40b0970f91cb923423773f72fe1702f.898baac75d55d484b1b1de95b8ab791987c78591acf36ce6131b56d0d2d26af7\n",
            "Model config LEDConfig {\n",
            "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"LEDForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_window\": [\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_decoder_position_embeddings\": 1024,\n",
            "  \"max_encoder_position_embeddings\": 16384,\n",
            "  \"model_type\": \"led\",\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/led-base-16384/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ec844bead6f5bbcd6ac727b57e595c2ba40b0970f91cb923423773f72fe1702f.898baac75d55d484b1b1de95b8ab791987c78591acf36ce6131b56d0d2d26af7\n",
            "Model config LEDConfig {\n",
            "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"LEDForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_window\": [\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_decoder_position_embeddings\": 1024,\n",
            "  \"max_encoder_position_embeddings\": 16384,\n",
            "  \"model_type\": \"led\",\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_input_length = 1024\n",
        "max_output_length = 1024\n",
        "Batch_size = 4\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "    # tokenize the inputs and labels\n",
        "    inputs = tokenizer(\n",
        "        batch[\"summary\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_input_length,\n",
        "    )\n",
        "    outputs = tokenizer(\n",
        "        batch[\"content\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_output_length,\n",
        "    )\n",
        "    batch[\"input_ids\"] = inputs.input_ids\n",
        "    batch[\"attention_mask\"] = inputs.attention_mask\n",
        "    batch[\"global_attention_mask\"] = len(batch[\"input_ids\"]) * [\n",
        "        [1 for _ in range(len(batch[\"input_ids\"][0]))]\n",
        "    ]\n",
        "    batch[\"global_attention_mask\"][0][0]=1\n",
        "    batch[\"labels\"] = outputs.input_ids\n",
        "\n",
        "    batch[\"labels\"] = [\n",
        "       [-100 if token == tokenizer.pad_token_id else token for token in labels]\n",
        "       for labels in batch[\"labels\"]\n",
        "    ]\n",
        "    return batch"
      ],
      "metadata": {
        "id": "Cz2zWDq5PL6H"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train, validate,test = np.split(tempDf.sample(frac=1, random_state=42), [int(.4*len(tempDf)), int(.5*len(tempDf))])\n",
        "print(train.shape)\n",
        "print(validate.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uObEuG0QrBh",
        "outputId": "41699050-24f0-4343-d2c0-2a19ce85fee6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(214, 4)\n",
            "(54, 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=train[0:250]\n",
        "validate=validate[25:50]\n",
        "print(train.shape)\n",
        "print(validate.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WWeImXWQ_D8",
        "outputId": "b8f17c2b-b93e-4033-d2bf-0462166b14c3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(214, 4)\n",
            "(25, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "train_dataset = Dataset.from_pandas(train)\n",
        "validate_dataset = Dataset.from_pandas(validate)"
      ],
      "metadata": {
        "id": "URd13aMrRQcB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=Batch_size,\n",
        "    remove_columns=[\"content\",\"summary\",\"length\",\"__index_level_0__\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c412b4130e754f30a8671aff28cec72b",
            "38a10ec14d724ce6ba74cd22942dcea9",
            "6f9450db9cfd4fd1963561b3ba38f387",
            "e3d435cd5ac14ae395a9672ae7d3f514",
            "ec91081ec2584ab39cc3ee5a873b0893",
            "feff141b3b8f4833ab0d8bf7fd49e84d",
            "1601e80577f64136be6a7a0102a8d4de",
            "fb1de689d27c47cd8a79195737df2cea",
            "698333caa2364f3daffdfd79d9421585",
            "d4aecdd386bc46888e984f684fbd3192",
            "316a93efe6984c6585f02ffda6e4d1a3"
          ]
        },
        "id": "1XFs7b9aRVwa",
        "outputId": "11701dfd-be6a-40b3-f64f-61c371c2bea6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/214 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c412b4130e754f30a8671aff28cec72b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_dataset = validate_dataset.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=Batch_size,\n",
        "    remove_columns=[\"content\",\"summary\",\"length\",\"__index_level_0__\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "32acd1a64282401b98d2e3d200db6f05",
            "5a9f58c1d4ac4b74985f8bf137f96b2f",
            "43cb02f3f70043ceb787c03eb63d7ed7",
            "296ad9aef3264b9b90c32d59229d10b9",
            "91ad8ab6a9874fd3b921306d0c71c871",
            "a1af8c8d8b8543e09d3959bed7eafef6",
            "6cde556aca28433ea77287f1b2f54ad0",
            "7391cd2e1bc749d7bfead18bc5180343",
            "1744ed5f1dc94424b0cd9ca52b9d2f64",
            "972e2c1f9c1a477ba3f19fb96414f2a5",
            "2d42e2b84e9d4600aee646ea60f8678c"
          ]
        },
        "id": "260CH1YQRXuZ",
        "outputId": "8ca748a4-bd62-4a6c-c367-8559852b9eaa"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32acd1a64282401b98d2e3d200db6f05"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
        ")\n",
        "val_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
        ")"
      ],
      "metadata": {
        "id": "BI-OpW6URZ7F"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "led=AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\",gradient_checkpointing=True,use_cache=False)\n",
        "led.config.num_beams=2\n",
        "led.config.max_length=1024\n",
        "led.config.min_length=512\n",
        "led.config.length_penalty=2.0\n",
        "led.config.early_stopping=True\n",
        "led.config.no_repeat_ngram_size=3\n",
        "\n",
        "rouge =load_metric(\"rouge\")\n",
        "\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels_ids=pred.label_ids\n",
        "    pred_ids=pred.predictions\n",
        "\n",
        "    pred_str=tokenizer.batch_decode(pred_ids,skip_special_tokens=True)\n",
        "    labels_ids[labels_ids==-100]=tokenizer.pad_token_id\n",
        "    label_str=tokenizer.batch_decode(labels_ids,skip_special_tokens=True)\n",
        "\n",
        "    rouge_output=rouge.compute(predictions=pred_str,references=label_str,rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
        "\n",
        "    return {\n",
        "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=Batch_size,\n",
        "    per_device_eval_batch_size=Batch_size,\n",
        "\n",
        "    output_dir=\"./\",\n",
        "    logging_steps=5,\n",
        "    save_steps=10,\n",
        "    eval_steps=10,\n",
        "    save_total_limit=2,\n",
        "\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=2\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3UdaF42RdCA",
        "outputId": "b9dab697-abc3-4e89-bed8-bb289f8275b1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/allenai/led-base-16384/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ec844bead6f5bbcd6ac727b57e595c2ba40b0970f91cb923423773f72fe1702f.898baac75d55d484b1b1de95b8ab791987c78591acf36ce6131b56d0d2d26af7\n",
            "Model config LEDConfig {\n",
            "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"LEDForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_window\": [\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": true,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_decoder_position_embeddings\": 1024,\n",
            "  \"max_encoder_position_embeddings\": 16384,\n",
            "  \"model_type\": \"led\",\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/led-base-16384/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/c8f7e4603efbc329ce921b34057d78880dead50f45b2a1648b3a06ca6eb17f51.201222b06d46289037a8dccc57548abc8eb81ba042d3762214ac15c9691ff8c7\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:392: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "All model checkpoint weights were used when initializing LEDForConditionalGeneration.\n",
            "\n",
            "All the weights of LEDForConditionalGeneration were initialized from the model checkpoint at allenai/led-base-16384.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LEDForConditionalGeneration for predictions without further training.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer=Seq2SeqTrainer(\n",
        "    model=led,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "NAaf17H-TJ0W"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "kWhN0oa1Tr-4",
        "outputId": "aeee37db-4e94-4855-dd70-85e5eedddd4d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `LEDForConditionalGeneration.forward` and have been ignored: title. If title are not expected by `LEDForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 214\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 26\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 786.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 577.06 MiB is free. Process 7360 has 14.18 GiB memory in use. Of the allocated memory 12.11 GiB is allocated by PyTorch, and 1.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         )\n\u001b[0;32m-> 1317\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1318\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1552\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2199\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2201\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 786.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 577.06 MiB is free. Process 7360 has 14.18 GiB memory in use. Of the allocated memory 12.11 GiB is allocated by PyTorch, and 1.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = tempDf.sample(frac=0.005, random_state=12)\n",
        "sample.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDuEojXmT8ju",
        "outputId": "99b7d18d-00ea-4653-ef20-ec611f24cc50"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = sample[['content','summary']]\n",
        "sample['content']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "rNcw621eUJH0",
        "outputId": "55dd8acd-1d7a-44a8-8b6e-71422b40ec41"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "935    “Keep a notebook. Travel with it, eat with it,...\n",
              "816    How Ad Limits Will Work on Facebook<|n|><|n|>T...\n",
              "38     3 Marketing Strategies That Can Work Like Magi...\n",
              "Name: content, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>“Keep a notebook. Travel with it, eat with it,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>How Ad Limits Will Work on Facebook&lt;|n|&gt;&lt;|n|&gt;T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>3 Marketing Strategies That Can Work Like Magi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample['summary']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "eVKJ3Jz9UR42",
        "outputId": "cf0c7d70-92d5-4bed-c801-f8562a7f9cce"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "935    Slap into it every stray thought that flutters...\n",
              "816    How Ad Limits Will Work on Facebook<|n|><|n|>T...\n",
              "38     With the world getting smaller day by day, it’...\n",
              "Name: summary, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>Slap into it every stray thought that flutters...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>How Ad Limits Will Work on Facebook&lt;|n|&gt;&lt;|n|&gt;T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>With the world getting smaller day by day, it’...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "pubmed_test=Dataset.from_pandas(sample)\n",
        "import torch\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = LEDTokenizer.from_pretrained(\"/content/runs/Sep08_07-13-34_99ab2af7b599/1725779621.5996437\")\n",
        "model = LEDForConditionalGeneration.from_pretrained(\"/content/runs/Sep08_07-13-34_99ab2af7b599/1725780815.0933282/events.out.tfevents.1725780815.99ab2af7b599.620.2\").to(device).half()\n",
        "def generate_answer(batch):\n",
        "    inputs_dict = tokenizer(\n",
        "        batch[\"summary\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=1024,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = inputs_dict.input_ids.to(device)\n",
        "    attention_mask = inputs_dict.attention_mask.to(device)\n",
        "    global_attention_mask = torch.zeros_like(attention_mask)\n",
        "\n",
        "    predicated_abstract_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        global_attention_mask=global_attention_mask)\n",
        "    batch[\"predicated_content\"] = tokenizer.batch_decode(\n",
        "        predicated_abstract_ids, skip_special_tokens=True\n",
        "    )\n",
        "    return batch\n",
        "result =pubmed_test.map(generate_answer, batched=True, batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "7WwU5GbeUk45",
        "outputId": "af208e20-0849-40e9-e5b9-0bd3ba6fd64a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Didn't find file /content/runs/Sep08_07-13-34_99ab2af7b599/1725779621.5996437/vocab.json. We won't load it.\n",
            "Didn't find file /content/runs/Sep08_07-13-34_99ab2af7b599/1725779621.5996437/merges.txt. We won't load it.\n",
            "Didn't find file /content/runs/Sep08_07-13-34_99ab2af7b599/1725779621.5996437/added_tokens.json. We won't load it.\n",
            "Didn't find file /content/runs/Sep08_07-13-34_99ab2af7b599/1725779621.5996437/special_tokens_map.json. We won't load it.\n",
            "Didn't find file /content/runs/Sep08_07-13-34_99ab2af7b599/1725779621.5996437/tokenizer_config.json. We won't load it.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Can't load tokenizer for '/content/runs/Sep08_07-13-34_99ab2af7b599/1725779621.5996437'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/content/runs/Sep08_07-13-34_99ab2af7b599/1725779621.5996437' is the correct path to a directory containing all relevant files for a LEDTokenizer tokenizer.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-4ac851642dde>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEDTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/runs/Sep08_07-13-34_99ab2af7b599/1725779621.5996437\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEDForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/runs/Sep08_07-13-34_99ab2af7b599/1725780815.0933282/events.out.tfevents.1725780815.99ab2af7b599.620.2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m   1769\u001b[0m                 \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m                 \u001b[0;34m\"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for '/content/runs/Sep08_07-13-34_99ab2af7b599/1725779621.5996437'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/content/runs/Sep08_07-13-34_99ab2af7b599/1725779621.5996437' is the correct path to a directory containing all relevant files for a LEDTokenizer tokenizer."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['content'][1]\n"
      ],
      "metadata": {
        "id": "jB_xP5gaVdNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['predicated_content'][1]"
      ],
      "metadata": {
        "id": "wYGFshUiVf_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}